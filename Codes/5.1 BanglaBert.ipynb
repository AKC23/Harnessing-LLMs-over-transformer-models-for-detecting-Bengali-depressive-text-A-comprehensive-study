{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMYCLTOS+c4uVSPUL6ssSPF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"s7AqExEj59Vp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687328751239,"user_tz":-360,"elapsed":22545,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"1d7a9b05-9052-4440-c57b-5de21c260977"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["%cd drive/MyDrive/Colab Notebooks/Thesis Project/"],"metadata":{"id":"tBZA5wtV6CMS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687328751240,"user_tz":-360,"elapsed":6,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"7fc83b5c-506c-4a11-d9b3-3cd972b33b2a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Thesis Project\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"M5R3b9KJ6CJq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686276125683,"user_tz":-360,"elapsed":731,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"006d5792-124f-4f89-aa18-7e3a99083e62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'0. Depression Analysis Dataset.xlsx'\n","'1. Depression Analysis Dataset Cleaned v1.xlsx'\n","'1. Depression Analysis Dataset Cleaned v2.xlsx'\n","'1. Depression Analysis Dataset Cleaned v3_textcleaned.xlsx'\n","'1. Depression Analysis Dataset Cleaned v3_textstemmed.xlsx'\n","'1. Depression Analysis v1.ipynb'\n","'2.1 Depression Analysis v2 (Previous code).ipynb'\n","'2.2 Depression Analysis v2.ipynb'\n","'2.3 Depression Analysis v2 modified.ipynb'\n","'3.1 Depression_Analysis_v3.ipynb'\n","'3.2 Depression_Analysis_v3 (Word2Vec).ipynb'\n","'3.3 Depression_Analysis_v3 (FastText).ipynb'\n","'3.4 Depression_Analysis_LSTM_FastText.ipynb'\n","'3.4 Depression_Analysis_v3 (Glove).ipynb'\n","'3.5 Depression_Analysis_BiLSTM_FastText.ipynb'\n","'4.1 Depression_Analysis_v4 (New Tokenizer).ipynb'\n","'4.2 Depression_Analysis_v4_Lemmatize.ipynb'\n","'4.3 Depression_Analysis_v4_Stem.ipynb'\n","'4.4 Depression_Analysis (Hyperparameter Tuning).ipynb'\n","'5. BanglaBert.ipynb'\n"," content\n","'Depression_Analysis (Bayesian Optimization).ipynb'\n"," preprocessed_dataset.csv\n"," state_dict.pt\n"]}]},{"cell_type":"code","source":["pip install transformers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2gBXwz3K1_pj","executionInfo":{"status":"ok","timestamp":1686276140526,"user_tz":-360,"elapsed":14845,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"163164ca-a518-4aef-d450-b88c2299c56a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.0\n"]}]},{"cell_type":"code","source":["#import libraries\n","import numpy as np\n","import pandas as pd\n","import random\n","import re, string\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","#PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from sklearn.model_selection import train_test_split\n","\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n"],"metadata":{"id":"RqePl4kK1HgF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the dataset\n","df = pd.read_excel('1. Depression Analysis Dataset Cleaned v2.xlsx')\n","df.head()"],"metadata":{"id":"RPFuzHQ-6CHL","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1686276154395,"user_tz":-360,"elapsed":3407,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"665ce5aa-50bd-448a-ce2e-b5bfb424d7f7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text  label\n","0  লক্ষ্য জীবনের মূল্য সারাদিন কাটাই দুঃখ বেদনায়...      1\n","1  ক্রমাগত নিজেকে পুনরাবৃত্তি লড়াই সুযোগ সত্যই প...      1\n","2  বয়সী বয়স বিষণ্নতায় গভীরভাবে বেড়ে উঠেছি কঠি...      1\n","3  তুরস্কে বসবাসকারী বয়স সম্ভবত পোস্ট করছি সিদ্ধ...      1\n","4  কিছুক্ষণ ঘটেছিল বিরক্ত সাহায্য কথা নোংরা সত্যি...      1"],"text/html":["\n","  <div id=\"df-010071fa-0ad2-4f2c-bf6e-5cd611c2c76a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>লক্ষ্য জীবনের মূল্য সারাদিন কাটাই দুঃখ বেদনায়...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ক্রমাগত নিজেকে পুনরাবৃত্তি লড়াই সুযোগ সত্যই প...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>বয়সী বয়স বিষণ্নতায় গভীরভাবে বেড়ে উঠেছি কঠি...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>তুরস্কে বসবাসকারী বয়স সম্ভবত পোস্ট করছি সিদ্ধ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>কিছুক্ষণ ঘটেছিল বিরক্ত সাহায্য কথা নোংরা সত্যি...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-010071fa-0ad2-4f2c-bf6e-5cd611c2c76a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-010071fa-0ad2-4f2c-bf6e-5cd611c2c76a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-010071fa-0ad2-4f2c-bf6e-5cd611c2c76a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df.to_csv('preprocessed_dataset.csv', index=False)\n"],"metadata":{"id":"QX7yrPiM6CCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load preprocessed dataset\n","df = pd.read_csv('preprocessed_dataset.csv')\n","\n","# Split dataset into training and evaluation sets\n","train_df, eval_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# Load the BanglaBERT tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('sagorsarker/bangla-bert-base')"],"metadata":{"id":"CawwywBG6B_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the maximum sequence length\n","max_seq_length = 512\n","\n","# Tokenize and encode text data with max length\n","train_encodings = tokenizer(list(train_df['text']), truncation=True, padding='max_length', max_length=max_seq_length)\n","eval_encodings = tokenizer(list(eval_df['text']), truncation=True, padding='max_length', max_length=max_seq_length)\n","\n","# Convert encodings to tensors\n","train_input_ids = torch.tensor(train_encodings['input_ids'])\n","train_attention_mask = torch.tensor(train_encodings['attention_mask'])\n","eval_input_ids = torch.tensor(eval_encodings['input_ids'])\n","eval_attention_mask = torch.tensor(eval_encodings['attention_mask'])\n","\n","# Convert labels to tensors\n","train_labels = torch.tensor(list(train_df['label']))\n","eval_labels = torch.tensor(list(eval_df['label']))\n","\n","# Create PyTorch datasets\n","train_dataset = torch.utils.data.TensorDataset(train_input_ids, train_attention_mask, train_labels)\n","eval_dataset = torch.utils.data.TensorDataset(eval_input_ids, eval_attention_mask, eval_labels)\n"],"metadata":{"id":"WxwXQWkl5oOd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the BanglaBERT model for sequence classification\n","model = AutoModelForSequenceClassification.from_pretrained('sagorsarker/bangla-bert-base', num_labels=2)\n","\n","# Set up the optimizer\n","optimizer = AdamW(model.parameters(), lr=1e-3)\n","\n","# Set up the data loaders\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n","eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=8, shuffle=False)\n","\n","# Fine-tuning BanglaBERT\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwCXnItZ5pk4","executionInfo":{"status":"ok","timestamp":1686276372605,"user_tz":-360,"elapsed":4581,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"b6778592-94bf-4c83-c7ad-8129173e6b50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sagorsarker/bangla-bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(102025, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["for epoch in range(3):  # Set the number of training epochs\n","    model.train()\n","    for batch in train_loader:\n","        input_ids, attention_mask, labels = batch\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","\n","    model.eval()\n","    eval_accuracy = 0\n","    eval_loss = 0\n","    with torch.no_grad():\n","        for batch in eval_loader:\n","            input_ids, attention_mask, labels = batch\n","            input_ids = input_ids.to(device)\n","            attention_mask = attention_mask.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","            logits = outputs.logits\n","\n","            eval_loss += outputs.loss.item()\n","            eval_accuracy += (logits.argmax(dim=1) == labels).float().mean().item()\n","\n","    eval_loss /= len(eval_loader)\n","    eval_accuracy /= len(eval_loader)\n","    print(f\"Epoch {epoch+1}: Evaluation Loss: {eval_loss}, Evaluation Accuracy: {eval_accuracy}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Z1DH-0l44L8","executionInfo":{"status":"ok","timestamp":1686280559966,"user_tz":-360,"elapsed":4172424,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"d04e0988-584f-4f36-ffbd-8b4dfb8263c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Evaluation Loss: 0.9217860773371694, Evaluation Accuracy: 0.5101018135823757\n","Epoch 2: Evaluation Loss: 0.6934935763843341, Evaluation Accuracy: 0.5101018135823757\n","Epoch 3: Evaluation Loss: 0.6933695972629539, Evaluation Accuracy: 0.5101018135823757\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mO90X8pA3X7j"},"execution_count":null,"outputs":[]}]}