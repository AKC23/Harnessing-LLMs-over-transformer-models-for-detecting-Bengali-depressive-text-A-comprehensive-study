{"cells":[{"cell_type":"markdown","source":["\n","\n","1.   Import Package\n","2.   Data Cleaning and processing\n","3.   Word Embedding (Word2Vec)\n","2.   Implemented LSTM\n","2.   Implement BiLSTM\n"],"metadata":{"id":"jrFh8RQg1Ufv"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vk545Wahz53e","outputId":"3cf46df5-324a-4fd9-aaa1-a5b73ddb26a5","executionInfo":{"status":"ok","timestamp":1683276007931,"user_tz":-360,"elapsed":22112,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: bnlp in /usr/local/lib/python3.10/dist-packages (0.8)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: bnlp_toolkit in /usr/local/lib/python3.10/dist-packages (3.3.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.10.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.65.0)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.3.1)\n","Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (0.3.6)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (0.1.99)\n","Requirement already satisfied: emoji==1.7.0 in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.7.0)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (6.1.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.22.4)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->bnlp_toolkit) (0.2.6)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bnlp_toolkit) (6.3.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (8.1.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (2022.10.31)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.8.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (1.16.0)\n","Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.9)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: bnlp_toolkit in /usr/local/lib/python3.10/dist-packages (3.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.22.4)\n","Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (0.3.6)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.3.1)\n","Requirement already satisfied: emoji==1.7.0 in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.7.0)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (6.1.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.10.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.65.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (3.8.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (0.1.99)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->bnlp_toolkit) (0.2.6)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bnlp_toolkit) (6.3.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (2022.10.31)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (8.1.3)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.8.10)\n","Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (1.16.0)\n"]}],"source":["#install libraries\n","!pip install bnlp\n","!pip install bnlp_toolkit\n","!pip install --upgrade bnlp_toolkit"]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')"],"metadata":{"id":"uDTSa8AMUcv6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683276009053,"user_tz":-360,"elapsed":1129,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"379046c5-28b0-472e-c4cd-27088c70bb6f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["pip install fasttext"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44KHJf7cj5Wz","executionInfo":{"status":"ok","timestamp":1683276012902,"user_tz":-360,"elapsed":3864,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"b33639b8-58f4-4efb-d757-3e8a0d637c55"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.22.4)\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.10.4)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gy9-lOlL0IMX","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"e7fb98bf-ac36-453d-ebde-607176194517","executionInfo":{"status":"ok","timestamp":1683276016088,"user_tz":-360,"elapsed":3189,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-7d5d335e6a9c>:20: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n","  plt.style.use(\"seaborn-whitegrid\")\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{}}],"source":["#import libraries\n","import numpy as np\n","import pandas as pd\n","import random\n","import re, string\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from string import punctuation\n","from bnlp import BasicTokenizer\n","from bnlp import NLTKTokenizer\n","from bnlp import SentencepieceTokenizer\n","from bnlp.corpus import stopwords, punctuations, letters, digits\n","from bnlp.corpus.util import remove_stopwords\n","from bnlp import BengaliWord2Vec\n","\n","#set style for plots\n","sns.set_style(\"whitegrid\")\n","sns.despine()\n","plt.style.use(\"seaborn-whitegrid\")\n","plt.rc(\"figure\", autolayout=True)\n","plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlepad=10)\n","\n","#Data preprocessing\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import RandomOverSampler\n","\n","#Naive Bayes\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.naive_bayes import MultinomialNB\n","\n","\n","#PyTorch LSTM\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#Tokenization for LSTM\n","from collections import Counter\n","from gensim.models import Word2Vec\n","\n","import gensim\n","from gensim.models import Word2Vec, FastText\n","import fasttext\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"]},{"cell_type":"markdown","source":["## Define Performance Metrics & Confusion Matrix "],"metadata":{"id":"Ck0m55kR7L2Y"}},{"cell_type":"code","source":["# Calculate performance metrics\n","def perf_matrix(y_test, y_pred):\n","  accuracy = accuracy_score(y_test, y_pred)\n","  precision = precision_score(y_test, y_pred, average='weighted')\n","  recall = recall_score(y_test, y_pred, average='weighted')\n","  f1 = f1_score(y_test, y_pred, average='weighted')\n","\n","  print('Accuracy:', accuracy)\n","  print('Precision:', precision)\n","  print('Recall:', recall)\n","  print('F1 Score:', f1)\n","\n","# Plot confusion matrix\n","def conf_matrix(y_test, y_pred, title, labels):\n","    fig, ax =plt.subplots(figsize=(4,4))\n","    ax=sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap=\"Greens\", fmt='g', cbar=True, annot_kws={\"size\":20})\n","    plt.title(title, fontsize=25)\n","    ax.xaxis.set_ticklabels(labels, fontsize=16) \n","    ax.yaxis.set_ticklabels(labels, fontsize=14.5)\n","    ax.set_ylabel('Test', fontsize=25)\n","    ax.set_xlabel('Predicted', fontsize=25)\n","    plt.show()"],"metadata":{"id":"9S6nIMfNly5I","executionInfo":{"status":"ok","timestamp":1683276016089,"user_tz":-360,"elapsed":4,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"abmz2SVq0cdf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683276020129,"user_tz":-360,"elapsed":4044,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"041a6715-9ce6-4883-fa63-9cc12fad4407"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"vuyfmyM33_HD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683276020129,"user_tz":-360,"elapsed":7,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"570289e9-5c61-4733-9ee9-ea301c07ca18"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Thesis Project\n"]}],"source":["%cd drive/MyDrive/Colab Notebooks/Thesis Project/"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"AYqbeuhq4m4s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683276021105,"user_tz":-360,"elapsed":980,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"3750dd2d-2992-4eba-ff21-3007279247f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["'0. Depression Analysis Dataset.xlsx'\n","'1. Depression Analysis Dataset Cleaned v1.xlsx'\n","'1. Depression Analysis Dataset Cleaned v2.xlsx'\n","'1. Depression Analysis Dataset Cleaned v3.xlsx'\n","'1. Depression Analysis v1.ipynb'\n","'2.1 Depression Analysis v2 (Previous code).ipynb'\n","'2.2 Depression Analysis v2.ipynb'\n","'2.3 Depression Analysis v2 modified.ipynb'\n","'3.1 Depression_Analysis_v3.ipynb'\n","'3.2 Depression_Analysis_v3 (FastText).ipynb'\n","'3.3 Depression_Analysis_LSTM_FastText.ipynb'\n","'3.4 Depression_Analysis_BiLSTM_FastText.ipynb'\n","'4. Depression_Analysis (Hyperparameter Tuning).ipynb'\n"," corpus.txt\n","'Depression_Analysis (Bayesian Optimization).ipynb'\n"," model_GRU.pth\n"," state_dict.pt\n"]}],"source":["!ls\n"]},{"cell_type":"markdown","source":["# Word Embedding (Fasttext)"],"metadata":{"id":"emAcqTi7crm0"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.sequence import pad_sequences"],"metadata":{"id":"bSTDXFwgC5Md","executionInfo":{"status":"ok","timestamp":1683276023530,"user_tz":-360,"elapsed":2427,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Load the data\n","df = pd.read_excel('1. Depression Analysis Dataset Cleaned v2.xlsx')\n","X = df['text']\n","\n","# Create a vocabulary of words from the data\n","corpus = [word for text in X for word in text.split()]\n","count_words = Counter(corpus)\n","sorted_words = count_words.most_common()\n","vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n","\n","# Save the text data to a file\n","with open('corpus.txt', 'w') as f:\n","    for text in X:\n","        f.write(text + '\\n')\n","\n","# Create a FastText model\n","model = fasttext.train_unsupervised('corpus.txt', model='skipgram', dim=200)\n","\n","# Initialize the embedding matrix\n","VOCAB_SIZE = len(vocab_to_int) + 1 #+1 for the padding\n","EMBEDDING_DIM = model.get_dimension()\n","embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n","\n","# Update the embedding matrix with the FastText embeddings\n","for word, i in vocab_to_int.items():\n","    embedding_matrix[i] = model.get_word_vector(word)\n","\n","# Print the shape of the embedding matrix\n","print(\"Embedding Matrix Shape:\", embedding_matrix.shape)\n","\n","# Tokenize the data using the vocabulary\n","text_int = []\n","for text in X:\n","    r = [vocab_to_int[word] for word in text.split()]\n","    text_int.append(r)\n","    \n","# Add padding to tokens\n","MAX_LEN = 5000\n","X = pad_sequences(text_int, maxlen=MAX_LEN, padding='post')\n","y = df['label'].values\n","\n","# Split the data into training, validation, and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3C4x9KSeMgt","executionInfo":{"status":"ok","timestamp":1683276366861,"user_tz":-360,"elapsed":343337,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"1a0cf098-07bd-431d-8512-414190d634d5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Embedding Matrix Shape: (63367, 200)\n"]}]},{"cell_type":"markdown","source":["# Data preprocessing for LSTM"],"metadata":{"id":"oFtbrvHaxVbw"}},{"cell_type":"code","source":["def Tokenize(column, seq_len):\n","    ##Create vocabulary of words from column\n","    corpus = [word for text in column for word in text.split()]\n","    count_words = Counter(corpus)\n","    sorted_words = count_words.most_common()\n","    vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n","\n","    ##Tokenize the columns text using the vocabulary\n","    text_int = []\n","    for text in column:\n","        r = [vocab_to_int[word] for word in text.split()]\n","        text_int.append(r)\n","    ##Add padding to tokens\n","    features = np.zeros((len(text_int), seq_len), dtype = int)\n","    for i, review in enumerate(text_int):\n","        if len(review) <= seq_len:\n","            zeros = list(np.zeros(seq_len - len(review)))\n","            new = zeros + review\n","        else:\n","            new = review[: seq_len]\n","        features[i, :] = np.array(new)\n","\n","    return sorted_words, features"],"metadata":{"id":"1POP-eu6upT9","executionInfo":{"status":"ok","timestamp":1683276366862,"user_tz":-360,"elapsed":14,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["max_len = 5000"],"metadata":{"id":"rXINA64i4BBG","executionInfo":{"status":"ok","timestamp":1683276366862,"user_tz":-360,"elapsed":13,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["vocabulary, tokenized_column = Tokenize(df[\"text\"], max_len)"],"metadata":{"id":"ltxGFX-TupRW","executionInfo":{"status":"ok","timestamp":1683276376294,"user_tz":-360,"elapsed":9445,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["vocabulary[:20]"],"metadata":{"id":"H7r79OUDupOl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683276376295,"user_tz":-360,"elapsed":45,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"ff4a4d10-f7bb-4f6e-8e39-51b52aa1101d"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('সাথে', 24522),\n"," ('না।', 18631),\n"," ('চাই', 14293),\n"," ('কথা', 11425),\n"," ('জানি', 11052),\n"," ('করেছি', 10807),\n"," ('সত্যিই', 9677),\n"," ('নিজেকে', 8401),\n"," ('করছি', 8398),\n"," ('সম্পর্কে', 8236),\n"," ('সময়', 8117),\n"," ('খারাপ', 7958),\n"," ('ভাল', 7829),\n"," ('অনুভব', 7206),\n"," ('শেষ', 6788),\n"," ('সাহায্য', 6154),\n"," ('জীবন', 6017),\n"," ('বোধ', 5876),\n"," ('বন্ধু', 5754),\n"," ('ছিলাম', 5544)]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["tokenized_column[3:6]"],"metadata":{"id":"OdfZ5jVPupL-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683276376295,"user_tz":-360,"elapsed":37,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"05227d52-7891-4846-ef04-21f9b861c7eb"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[    0,     0,     0, ...,   221,   325,     2],\n","       [    0,     0,     0, ...,    27,   377, 31353],\n","       [    0,     0,     0, ...,    23,   195,    91]])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["df[\"text\"].iloc[10]"],"metadata":{"id":"T_7CXkSeupJW","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1683276376295,"user_tz":-360,"elapsed":30,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"a0541a2c-76ec-4fc0-b7ad-c2db6fb60113"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'প্রথমে আপনাকে প্রশ্ন উপস্থাপন যাচ্ছি পারবেন। দিয়েছি আপনাকে সরবরাহ চাই গুরুতর বিষণ্নতা নেই। ভালোবাসো জীবনে ব্যক্তি সম্পর্কে চিন্তা আপনাকে বিরক্ত শ্রদ্ধার সাথে অপছন্দ উপলব্ধি হৃদয় পছন্দগুলির নিয়ন্ত্রণ কেবলমাত্র আপনারই পদক্ষেপের নির্দেশ ক্ষমতা বিশ্বের বিলিয়ন মানুষ ব্যক্তি সম্পর্কে চিন্তা যুক্তিসঙ্গত সন্দেহের বাইরে প্রমাণ চিন্তা পয়সা মিলিয়ন ডলারের ভগ্নাংশ কারণেই হতাশাকে যুক্তিযুক্ত লোকেরা সম্পর্কে অভিশাপ লোক পারেননি বাঁচাতে অবাধে জীবন দেবে। সবাই এভাবে মানুষ আপনাকে একজনের ভালবাসা দূরে সরিয়ে সাথে করেননি সময়ে জিততে দেবেন শুয়ে প্রতিটি পরিমাপে পরাজয় মেনে নিয়ন্ত্রণ দিয়েছেন। মুক্ত লোক সত্যিকারের মন্দ ময়লা চায়। আপনাকে মূল্যহীন বোধ লোক বন্ধুকে জিজ্ঞাসা আরে একা বোধ কথা ব্যক্তিগতভাবে অনলাইন বন্ধুত্ব বাস্তব জীবনের বন্ধুদের সাথে। ক্যালিফোর্নিয়ায় পরিচিত গিয়েছিলাম অপবাদের কারণে সকলের ঘৃণা করে। হাল ছেড়ে পরিবর্তে ব্যাক করুন সদয় ড্রাইভটি বন্ধ না। আত্মহত্যা রূপ আত্ম করুণা আত্মঘৃণা আত্মবিদ্বেষের নয়। নিজেকে হত্যা কেবল তাদেরই ক্ষতি সত্যিকারের যত্ন নেয়। মারা গল্প শেয়ার ভালভাবে বুঝতে পারছেন সংগ্রামটি ভুল বৃদ্ধি বৃদ্ধি পাচ্ছে নীচে বাইরে নিরপরাধ লোকদের সাথে কীভাবে কাঁধের প্রয়োজনের সময় সাথে কীভাবে পারে। কাঁদতে উদাসীনতা ভালোবাসেন অতীত বর্তমান ভবিষ্যৎ কাল রাখবেন ড্রাইভ গল্প ছেড়ে এটিকে অবহেলা ইতিমধ্যেই জিততে পারেন। জীবন জীবনের শেয়ার ব্যক্তিগত অভিজ্ঞতা জানি জীবন কঠিন। তবুও হাল ছেড়ে রাজি মা দুশ্চরিত্রা ত্যাগকারীকে উত্থাপন করেননি। সেপ্টেম্বর তারিখের বন্ধু প্রমাণিত নাম সদস্যকে মুখোমুখি জেলে পাঠাননি। অপরাধমূলক অভিযোগ। ব্যক্তি প্যারোলের সম্ভাবনা ছাড়াই কারাগারে জীবন কাটাচ্ছেন। নামের আঘাতের কথা জানতাম না। আঘাত হত্যা চুক্তি। উল্লিখিত তারিখে ওষুধের ওভারডোজ করছিলাম প্রাণঘাতী সীমার চারগুণ। সিস্টেমে অ্যাসিডও পরীক্ষার ফলাফল ব্লাড রেডের বাইরে আসতে পারে। স্তর উড়িয়ে দিয়েছি। হত্যা বর্ণনার বিরুদ্ধে গেছে। ক্যালিকো চুল বাদামী চোখ জলপাই ত্বকের স্বর ছিল। বর্ণনাটি নীল চোখের সাদা আদা বাচ্চা। বাচ্চাটা ঘুমাচ্ছে বারবার আক্রমণ করেছে। আচ্ছা উপদেশ অচেতন সহযোগিতা নরকে পিসিপি ড্রাগ ভাল ধারণা সংক্ষেপে অনুভব করিনি। ছিটকে তিনটি ভয়ঙ্কর ব্যর্থ প্রচেষ্টার অবশেষে মাথায় বন্দুক রাখল। সাথে জানি বলেছিলাম করো। সবচেয়ে কাছের বন্ধুদের ডেকেছিলাম জানতাম হত্যা সময় সাথে সবাই মারা যাবে। যুক্তিটি উপস্থাপন করেছি বন্দুকটি পিছনে রেখেছিল ঘুষি ভাগ্য সিদ্ধান্ত নিয়েছে। প্রতিবারই তথ্য খাওয়ানোর ঘুরেছে অপেক্ষা করিনি দরকার ছিল। ক্রোধকে কণ্ঠে আঘাত অনুমতি দিয়েছিলাম কাঁপতে যাত্রী বন্দুকের পৌঁছানোর সাথে সাথে দিনের কোমায় রাখার জোরে আঘাত করি। ড্রাইভারের ফিরেছিলাম বিকল্পের সাথে উপস্থাপন করেছি থাকতাম কাছের শহরে চালান নয়তো আপনাকে মণ্ডে মারব। রাতের পূর্বে জ্ঞান জানতাম দরজার প্যানেলে বন্দুক কোথায় লোড বন্দুক রাখবেন বড়াই না। বারবার বন্দুকের পৌঁছেছিল এটিকে দিনের পাচ্ছিলাম। সেকেন্ডে হাতটি আঘাত বন্দুকটিকে স্পর্শ করেছিল। ডান দিকটি ভেঙে দিয়েছিলাম। চোয়ালটি পর্যায়ে অস্ত্রোপচারে হয়েছিল। পিছিয়ে পড়েছিলাম অসুস্থ বোধ করছিলাম মানুষের ক্ষতি ভক্ত সময়ে ক্লান্ত পড়েছিলাম। সৌভাগ্যবশত আঘাত করেছিলাম সক্ষম হয়েছিলাম পনের মিনিটের বিশ্রাম অবশেষে হোঁচট খেয়ে গাড়ি বেরিয়ে দৌড়ে যাই। নৌবাহিনীর কর্মীকে পেলাম রাস্তায় গাড়ি চালাচ্ছিলেন। দৌড়ে গেলাম সাহায্যের চিৎকার করলাম। অবশেষে বেরিয়ে ক্লান্ত ভয় পেয়েছিলাম সবে পারিনি। পরিচালনা পেরেছিলাম ডায়াল করেন। হাসপাতালে সিস্টেম বের নারকান ঘন্টা লেগেছিল। করেছি দুবার বিশ্রামাগার গেটোরেডের বোতল পান বোতল ছিল। ঘুমাতে হয়নি। মানসিক অবস্থার ছিলাম থাকার হ্যালুসিনেটিং না। প্রস্রাব বিশ্লেষণ আসে ইটের আঘাত করে। দেয়াল গলে হিংস্রভাবে স্থানান্তরিত মেঝে সমুদ্রের ঢেউয়ের উঠে কেবল বাড়িতে থাকতে চেয়েছিলাম। একা ভয় পেয়েছিলাম ফোন অনুমতি বিষয়ে ফোন না। মামলা পরিচালনার দায়িত্বে গোয়েন্দার সাথে কথা বলি হুমকি কোমায় পড়ে ব্যক্তিটি মারা মানবহত্যার অভিযোগের মুখোমুখি খুশি হামলা ব্যাটারির অভিযোগ আনা না। চোয়াল ভেঙ্গে ফেলেছি ছিটকে যাচ্ছিলাম। উল্লেখ করেছি যানবাহন ড্যাশ ক্যাম সংগ্রহ প্রমাণগুলি প্রমাণ আত্মরক্ষা ডোন্ট কেয়ার প্রতিক্রিয়া পেয়েছি। মজার বলকান স্ক্যান্ডিনেভিয়ান। বললাম পছন্দ করেনি বলেছিল সম্পর্কে দেখব। শেষ মামলাটি ইনসিনেরেটরে নিক্ষেপ অপহরণের পর্যায়ে আনতে পারিনি। তবুও প্রযুক্তি সেলফোন সিগন্যাল ট্রেস নম্বর বলেছিলাম প্রত্যাখ্যান করেছিল। নাম দিয়েছিলাম বলেছিলাম নেদারল্যান্ডের স্পেক অপ্সকে ফোন রক্ষা মুখের বলেছিলাম একটা কান্ট একটা দুর্নীতিগ্রস্ত আবর্জনার টুকরো ফায়ারিং স্কোয়াডের ঘটেছিল সাথে দূরবর্তীভাবে সকলকে সংযুক্ত কিছুতেই থামব এমনকি ঈশ্বরের কাছেও করেছিলাম চেনেন জানেন প্রতিশ্রুতি রাখি ঈশ্বরের কাছে। অবশেষে সবকিছুকে প্রশ্নবিদ্ধ করেছি নরকের আগুন গন্ধকের সময়। হতাশ অনেকগুলি সমস্যা এটির মধ্য পাওয়ার ঈশ্বরকে ধন্যবাদ জানাই। পছন্দে বিশ্বাস করুন। বাস্তব ঘটনা সত্যিই ঘটেছে। গিয়েছিলাম জীবনের এমনকি দূরবর্তীভাবে সংযুক্ত সকলকে শিকারের উৎসর্গ করেছি খুঁজে পেয়েছি পেটে অসুস্থ পড়েছে। ধর্ষণ শিশু শ্লীলতাহানি ফেডারেল সরকারের সাথে সরাসরি সংযোগ। সেকেন্ডের জন্যও ভাবিনি এতটা গভীর হবে। খরগোশের গর্তটি কতটা নিচে নেমে সত্যতা সম্পর্কে ধারণা না। নীচে গিয়েছিলাম এসেছি পরিবর্তন অনুমতি দেবেন মূল্যবান শ্রদ্ধা ভালবাসা উঠুন। লোকেরা আপনাকে হারানোর একমাত্র উপায় পারেন। ইউটিউব আক্রমণাত্মক প্রেরণামূলক বক্তৃতা সিংহের ছবি। লিখতে সাহায্য করেছি টুকরা কথা বলেছি শেয়ার প্রয়োজন'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["tokenized_column[10]"],"metadata":{"id":"6fGZOYtpupGu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683276376296,"user_tz":-360,"elapsed":28,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"3034fad3-c514-46d7-c0bd-7bc808984dc0"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  0,   0,   0, ..., 385, 514, 117])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["## Train - Validation - Test split"],"metadata":{"id":"zbG18mSpPsaR"}},{"cell_type":"code","source":["df.head(10)"],"metadata":{"id":"eO2hDuL3P_F5","executionInfo":{"status":"ok","timestamp":1683276376296,"user_tz":-360,"elapsed":24,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"colab":{"base_uri":"https://localhost:8080/","height":363},"outputId":"f8902f42-1f44-423d-d006-e345308c299b"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text  label\n","0  বয়সী বয়স বিষণ্নতায় গভীরভাবে বেড়ে উঠেছি। কঠ...      1\n","1  তুরস্কে বসবাসকারী একজন। বয়স সম্ভবত কম। পোস্ট ...      1\n","2  কিছুক্ষণ ঘটেছিল বিরক্ত সাহায্য কথা নোংরা করেছে...      1\n","3  পুরো জীবন মাসে স্বতঃস্ফূর্তভাবে জ্বলে উঠেছে। ব...      1\n","4  শীঘ্রই বয়সী। মুহুর্তে সিডি সামাজিক জীবনে বড় ...      1\n","5  মানসিক শারীরিকভাবে অসুস্থ ক্লান্ত। পুরো জীবন শ...      1\n","6  জানতাম সাথে ভুল ছিল। লোক খারাপ জীবন কাটিয়েছে ...      1\n","7  দয়া সাথে থাকুন অত্যন্ত দীর্ঘ আপনাকে পড়তে উত্...      1\n","8  অনেটিভ ইংরেজি স্পিকারের অনুসরণ বিরক্তিকর অপ্রত...      1\n","9  দৈর্ঘ্যের ক্ষমাপ্রার্থী। বোঝানোর বের আলিঙ্গন ব...      1"],"text/html":["\n","  <div id=\"df-9e0b1df1-e397-4715-8f79-c5e52b7a11cc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>বয়সী বয়স বিষণ্নতায় গভীরভাবে বেড়ে উঠেছি। কঠ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>তুরস্কে বসবাসকারী একজন। বয়স সম্ভবত কম। পোস্ট ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>কিছুক্ষণ ঘটেছিল বিরক্ত সাহায্য কথা নোংরা করেছে...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>পুরো জীবন মাসে স্বতঃস্ফূর্তভাবে জ্বলে উঠেছে। ব...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>শীঘ্রই বয়সী। মুহুর্তে সিডি সামাজিক জীবনে বড় ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>মানসিক শারীরিকভাবে অসুস্থ ক্লান্ত। পুরো জীবন শ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>জানতাম সাথে ভুল ছিল। লোক খারাপ জীবন কাটিয়েছে ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>দয়া সাথে থাকুন অত্যন্ত দীর্ঘ আপনাকে পড়তে উত্...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>অনেটিভ ইংরেজি স্পিকারের অনুসরণ বিরক্তিকর অপ্রত...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>দৈর্ঘ্যের ক্ষমাপ্রার্থী। বোঝানোর বের আলিঙ্গন ব...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e0b1df1-e397-4715-8f79-c5e52b7a11cc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9e0b1df1-e397-4715-8f79-c5e52b7a11cc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9e0b1df1-e397-4715-8f79-c5e52b7a11cc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["X = tokenized_column\n","y = df['label'].values\n","y"],"metadata":{"id":"Xm2QQ0MMuowG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683276376296,"user_tz":-360,"elapsed":23,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"8f81b656-b3ca-4d6c-c52c-4af10d28ce13"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, ..., 0, 0, 0])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"],"metadata":{"id":"nPmv5reHuoto","executionInfo":{"status":"ok","timestamp":1683276377534,"user_tz":-360,"elapsed":1258,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train)"],"metadata":{"id":"QtgEhIFQuoYQ","executionInfo":{"status":"ok","timestamp":1683276377534,"user_tz":-360,"elapsed":7,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["(unique, counts) = np.unique(y_train, return_counts=True)\n","np.asarray((unique, counts)).T"],"metadata":{"id":"Hge0LMcZPp2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683276377535,"user_tz":-360,"elapsed":8,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"f23cbb9f-b158-4b9f-a692-34846a36eb09"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   0, 6462],\n","       [   1, 6462]])"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["# PyTorch datasets and dataloaders"],"metadata":{"id":"a-OVcryXQY_h"}},{"cell_type":"code","source":["BATCH_SIZE = 8\n","EPOCHS = 5 #Number of training epoch\n","LR = 0.003 #Learning rate\n","DROPOUT = 0.5 #LSTM Dropout\n","WEIGHT_DECAY = 0.003\n","LSTM_LAYERS = 2 #Number of stacked LSTM layers\n","HIDDEN_DIM = 100 #number of neurons of the internal state (internal neural network in the LSTM)\n","\n","NUM_CLASSES = 2 #We are dealing with a multiclass classification of 2 classes\n","BIDIRECTIONAL = True #Boolean value to choose if to use a bidirectional LSTM or not\n","\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"pcwU8OH8TF6A","executionInfo":{"status":"ok","timestamp":1683276377535,"user_tz":-360,"elapsed":6,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n","test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n","valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))"],"metadata":{"id":"56JiNIpzQWL0","executionInfo":{"status":"ok","timestamp":1683276377535,"user_tz":-360,"elapsed":6,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True) \n","valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n","test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"],"metadata":{"id":"qhNh5z8LQWG6","executionInfo":{"status":"ok","timestamp":1683276377536,"user_tz":-360,"elapsed":7,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["## PyTorch BiLSTM modeling"],"metadata":{"id":"HcgaOiuPQtag"}},{"cell_type":"code","source":["class BiLSTM_Sentiment_Classifier(nn.Module):\n","\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, lstm_layers, bidirectional,batch_size, dropout):\n","        super(BiLSTM_Sentiment_Classifier,self).__init__()\n","        \n","        self.lstm_layers = lstm_layers\n","        self.num_directions = 2 if bidirectional else 1\n","        self.hidden_dim = hidden_dim\n","        self.num_classes = num_classes\n","        self.batch_size = batch_size\n","        \n","\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        self.lstm = nn.LSTM(embedding_dim,\n","                            hidden_dim,\n","                            num_layers=lstm_layers,\n","                            dropout=dropout,\n","                            bidirectional=bidirectional,\n","                            batch_first=True)\n","\n","        self.fc = nn.Linear(hidden_dim*self.num_directions, num_classes)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","        \n","    def forward(self, x, hidden):\n","        self.batch_size = x.size(0)\n","        ##EMBEDDING LAYER\n","        embedded = self.embedding(x)\n","        #LSTM LAYERS\n","        out, hidden = self.lstm(embedded, hidden)\n","        #Extract only the hidden state from the last LSTM cell\n","        out = out[:,-1,:]\n","        #FULLY CONNECTED LAYERS\n","        out = self.fc(out)\n","        out = self.softmax(out)\n","\n","        return out, hidden\n","\n","    def init_hidden(self, batch_size):\n","        #Initialization of the LSTM hidden and cell states\n","        h0 = torch.zeros((self.lstm_layers*self.num_directions, batch_size, self.hidden_dim)).detach().to(DEVICE)\n","        c0 = torch.zeros((self.lstm_layers*self.num_directions, batch_size, self.hidden_dim)).detach().to(DEVICE)\n","        hidden = (h0, c0)\n","        return hidden"],"metadata":{"id":"EFzYsj2bQWB5","executionInfo":{"status":"ok","timestamp":1683276377536,"user_tz":-360,"elapsed":6,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["model = BiLSTM_Sentiment_Classifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM,NUM_CLASSES, LSTM_LAYERS,BIDIRECTIONAL, BATCH_SIZE, DROPOUT)\n","model = model.to(DEVICE)\n","\n","#Initialize embedding with the previously defined embedding matrix\n","model.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n","#Allow the embedding matrix to be fined tuned to better adapt to out dataset and get higher accuracy\n","model.embedding.weight.requires_grad=True\n","\n","print(model)"],"metadata":{"id":"DrL26Ly4QV_J","executionInfo":{"status":"ok","timestamp":1683276387567,"user_tz":-360,"elapsed":10036,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3eeb3bcf-9ff4-4d51-ba6d-0b387c3b7a3c"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["BiLSTM_Sentiment_Classifier(\n","  (embedding): Embedding(63367, 200)\n","  (lstm): LSTM(200, 100, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n","  (fc): Linear(in_features=200, out_features=2, bias=True)\n","  (softmax): LogSoftmax(dim=1)\n",")\n"]}]},{"cell_type":"code","source":["criterion = nn.NLLLoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay = WEIGHT_DECAY)"],"metadata":{"id":"S7TJS2dOLIob","executionInfo":{"status":"ok","timestamp":1683276387567,"user_tz":-360,"elapsed":3,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["### BiLSTM Training loop "],"metadata":{"id":"TF4ZOQZIRNlA"}},{"cell_type":"code","source":["total_step = len(train_loader)\n","total_step_val = len(valid_loader)\n","\n","early_stopping_patience = 4\n","early_stopping_counter = 0\n","\n","valid_acc_max = 0 # Initialize best accuracy top 0\n","\n","for e in range(EPOCHS):\n","\n","    #lists to host the train and validation losses of every batch for each epoch\n","    train_loss, valid_loss  = [], []\n","    #lists to host the train and validation accuracy of every batch for each epoch\n","    train_acc, valid_acc  = [], []\n","\n","    #lists to host the train and validation predictions of every batch for each epoch\n","    y_train_list, y_val_list = [], []\n","\n","    #initalize number of total and correctly classified texts during training and validation\n","    correct, correct_val = 0, 0\n","    total, total_val = 0, 0\n","    running_loss, running_loss_val = 0, 0\n","\n","\n","    ####TRAINING LOOP####\n","\n","    model.train()\n","\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE) #load features and targets in device\n","\n","        h = model.init_hidden(labels.size(0))\n","\n","        model.zero_grad() #reset gradients \n","\n","        output, h = model(inputs,h) #get output and hidden states from LSTM network\n","        \n","        loss = criterion(output, labels)\n","        loss.backward()\n","        \n","        running_loss += loss.item()\n","        \n","        optimizer.step()\n","\n","        y_pred_train = torch.argmax(output, dim=1) #get tensor of predicted values on the training set\n","        y_train_list.extend(y_pred_train.squeeze().tolist()) #transform tensor to list and the values to the list\n","        \n","        correct += torch.sum(y_pred_train==labels).item() #count correctly classified texts per batch\n","        total += labels.size(0) #count total texts per batch\n","\n","    train_loss.append(running_loss / total_step)\n","    train_acc.append(100 * correct / total)\n","\n","    ####VALIDATION LOOP####\n","    \n","    with torch.no_grad():\n","        \n","        model.eval()\n","        \n","        for inputs, labels in valid_loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","\n","            val_h = model.init_hidden(labels.size(0))\n","\n","            output, val_h = model(inputs, val_h)\n","\n","            val_loss = criterion(output, labels)\n","            running_loss_val += val_loss.item()\n","\n","            y_pred_val = torch.argmax(output, dim=1)\n","            y_val_list.extend(y_pred_val.squeeze().tolist())\n","\n","            correct_val += torch.sum(y_pred_val==labels).item()\n","            total_val += labels.size(0)\n","\n","        valid_loss.append(running_loss_val / total_step_val)\n","        valid_acc.append(100 * correct_val / total_val)\n","\n","    #Save model if validation accuracy increases\n","    if np.mean(valid_acc) >= valid_acc_max:\n","        torch.save(model.state_dict(), './state_dict.pt')\n","        print(f'Epoch {e+1}:Validation accuracy increased ({valid_acc_max:.6f} --> {np.mean(valid_acc):.6f}).  Saving model ...')\n","        valid_acc_max = np.mean(valid_acc)\n","        early_stopping_counter=0 #reset counter if validation accuracy increases\n","    else:\n","        print(f'Epoch {e+1}:Validation accuracy did not increase')\n","        early_stopping_counter+=1 #increase counter if validation accuracy does not increase\n","        \n","    if early_stopping_counter > early_stopping_patience:\n","        print('Early stopped at epoch :', e+1)\n","        break\n","    \n","    print(f'\\tTrain_loss : {np.mean(train_loss):.4f} Val_loss : {np.mean(valid_loss):.4f}')\n","    print(f'\\tTrain_acc : {np.mean(train_acc):.3f}% Val_acc : {np.mean(valid_acc):.3f}%')"],"metadata":{"id":"dB3WjsNqRGSA","executionInfo":{"status":"error","timestamp":1683277695296,"user_tz":-360,"elapsed":1307731,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"colab":{"base_uri":"https://localhost:8080/","height":588},"outputId":"e49c4a06-060a-4f6e-e280-e706c7a2b68d"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1:Validation accuracy increased (0.000000 --> 89.036313).  Saving model ...\n","\tTrain_loss : 0.3499 Val_loss : 0.2696\n","\tTrain_acc : 85.294% Val_acc : 89.036%\n","Epoch 2:Validation accuracy did not increase\n","\tTrain_loss : 0.1491 Val_loss : 0.3474\n","\tTrain_acc : 94.574% Val_acc : 88.547%\n","Epoch 3:Validation accuracy did not increase\n","\tTrain_loss : 0.0713 Val_loss : 0.4083\n","\tTrain_acc : 97.693% Val_acc : 88.338%\n","Epoch 4:Validation accuracy did not increase\n","\tTrain_loss : 0.0343 Val_loss : 0.5709\n","\tTrain_acc : 98.955% Val_acc : 86.103%\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-b9f020a3525f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Loading the best model\n","model.load_state_dict(torch.load('./state_dict.pt'))"],"metadata":{"id":"LLOTnZ5wT4lQ","executionInfo":{"status":"aborted","timestamp":1683277695297,"user_tz":-360,"elapsed":13,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### BiLSTM Testing"],"metadata":{"id":"pKselW8ST-my"}},{"cell_type":"code","source":["model.eval()\n","y_pred_list = []\n","y_test_list = []\n","for inputs, labels in test_loader:\n","    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","    test_h = model.init_hidden(labels.size(0))\n","\n","    output, val_h = model(inputs, test_h)\n","    y_pred_test = torch.argmax(output, dim=1)\n","    y_pred_list.extend(y_pred_test.squeeze().tolist())\n","    y_test_list.extend(labels.squeeze().tolist())"],"metadata":{"id":"7xB0yUy-RGO4","executionInfo":{"status":"aborted","timestamp":1683277695297,"user_tz":-360,"elapsed":12,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label = ['0','1']"],"metadata":{"id":"W41tTidsndGV","executionInfo":{"status":"aborted","timestamp":1683277695298,"user_tz":-360,"elapsed":13,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Classification Report for Bi-LSTM :\\n', classification_report(y_test_list, y_pred_list, target_names=label))"],"metadata":{"id":"hrbGZIXBRGLw","executionInfo":{"status":"aborted","timestamp":1683277695298,"user_tz":-360,"elapsed":13,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["perf_matrix(y_test_list, y_pred_list)\n","#conf_matrix(y_test_list,y_pred_list,'PyTorch Bi-LSTM Sentiment Analysis\\nConfusion Matrix', label)"],"metadata":{"id":"nUxnFK6bRGJA","executionInfo":{"status":"aborted","timestamp":1683277695298,"user_tz":-360,"elapsed":13,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}