{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"ae1730e6c5534d1bb52b8a412b55dcca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a8abd75c101c4dc88cd837093dc572e2","IPY_MODEL_1be35d76135f403c8a9bc4362f158c0e","IPY_MODEL_3d228f2335744a6690dd38b5dd94a7a4"],"layout":"IPY_MODEL_25df1b29975b49bc98424ec24e528029"}},"a8abd75c101c4dc88cd837093dc572e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9509f41abe348df97b98ab9317ee985","placeholder":"​","style":"IPY_MODEL_7d51b1cca053421bbe53b16acce06414","value":"Downloading (…)okenizer_config.json: 100%"}},"1be35d76135f403c8a9bc4362f158c0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfd2fdaefc2940c8ad2ed98813fa97ce","max":471,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4ee887abc6c24ffc943c37141656b6ee","value":471}},"3d228f2335744a6690dd38b5dd94a7a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c89634a3d2b54a1f8528a3a7f6faa8cf","placeholder":"​","style":"IPY_MODEL_dc55d166a2fb466a882231db36164821","value":" 471/471 [00:00&lt;00:00, 16.6kB/s]"}},"25df1b29975b49bc98424ec24e528029":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9509f41abe348df97b98ab9317ee985":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d51b1cca053421bbe53b16acce06414":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfd2fdaefc2940c8ad2ed98813fa97ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ee887abc6c24ffc943c37141656b6ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c89634a3d2b54a1f8528a3a7f6faa8cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc55d166a2fb466a882231db36164821":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14c4a9791c02450f9e2338cc1d3a2bef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a82adb2c0f3243d2a4f885e7d248021c","IPY_MODEL_54cf469d84b94df9bc0deac6fce02f73","IPY_MODEL_07d9fb1123c44d0fba5a0ae8aad1bfc5"],"layout":"IPY_MODEL_1e962b1540de4c8d9f33d54abd39238c"}},"a82adb2c0f3243d2a4f885e7d248021c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_187121d668e846b79cadd5dddc489518","placeholder":"​","style":"IPY_MODEL_df1f136d4d7046e2af1e5673b0d69ba7","value":"Downloading (…)/main/tokenizer.json: 100%"}},"54cf469d84b94df9bc0deac6fce02f73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6928c394db964421ac6f586c1a259c41","max":1721143,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8772d2689c9544fbabab25b6adb43bea","value":1721143}},"07d9fb1123c44d0fba5a0ae8aad1bfc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a90f8a518109468e92706a9a6b87814d","placeholder":"​","style":"IPY_MODEL_46c87449aba440b78a45c5b5ea320c24","value":" 1.72M/1.72M [00:00&lt;00:00, 11.3MB/s]"}},"1e962b1540de4c8d9f33d54abd39238c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"187121d668e846b79cadd5dddc489518":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df1f136d4d7046e2af1e5673b0d69ba7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6928c394db964421ac6f586c1a259c41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8772d2689c9544fbabab25b6adb43bea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a90f8a518109468e92706a9a6b87814d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46c87449aba440b78a45c5b5ea320c24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1aad02853c44c808a918dd0782f0418":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_00e98e5f24734258bd979b72a25b30ab","IPY_MODEL_9bb5a3240bbd4f7381d4410b66e46af3","IPY_MODEL_14dd20d2286d4c568ec4d36626127584"],"layout":"IPY_MODEL_f18d3d123e864456a72ce9374e8e8685"}},"00e98e5f24734258bd979b72a25b30ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e88cd13e794417e8330280f7bda8bc9","placeholder":"​","style":"IPY_MODEL_4eba0a2fd5c84775b88fe502bd4a57e5","value":"Downloading (…)cial_tokens_map.json: 100%"}},"9bb5a3240bbd4f7381d4410b66e46af3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30b82e7420ff4b4e8338c2b75c266f84","max":322,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19d2870acd75415db953f17dc5959cf3","value":322}},"14dd20d2286d4c568ec4d36626127584":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab22a99c524e4090b6952fe2e8325452","placeholder":"​","style":"IPY_MODEL_044f9139274a48acac6e8a174e5875f8","value":" 322/322 [00:00&lt;00:00, 12.5kB/s]"}},"f18d3d123e864456a72ce9374e8e8685":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e88cd13e794417e8330280f7bda8bc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4eba0a2fd5c84775b88fe502bd4a57e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30b82e7420ff4b4e8338c2b75c266f84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19d2870acd75415db953f17dc5959cf3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab22a99c524e4090b6952fe2e8325452":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"044f9139274a48acac6e8a174e5875f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b33181428664be49f3bd48dfef779ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec7c27b8b1ff4a09ae3b6030a3e54a99","IPY_MODEL_e28eb5d2ed1b4bd78fc802bc57d1c2d9","IPY_MODEL_3444371b56864d25ace90e243b0cb743"],"layout":"IPY_MODEL_ef7227b049fc4b80a18bacc240f8aea0"}},"ec7c27b8b1ff4a09ae3b6030a3e54a99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17f7ce7dee6a4338af9c2c4270f84c27","placeholder":"​","style":"IPY_MODEL_fca03ab899d3469ca0233cc8064d13f6","value":"Downloading (…)lve/main/config.json: 100%"}},"e28eb5d2ed1b4bd78fc802bc57d1c2d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dde5a1ca8db4510ad10cfab1864a4df","max":813,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5dfb41e19c7645019bea35e7c38bf706","value":813}},"3444371b56864d25ace90e243b0cb743":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2526846992fa42a6b8a3b1c51fb24da9","placeholder":"​","style":"IPY_MODEL_3d205433b8b04f2abcced7d68562c5b6","value":" 813/813 [00:00&lt;00:00, 30.0kB/s]"}},"ef7227b049fc4b80a18bacc240f8aea0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17f7ce7dee6a4338af9c2c4270f84c27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fca03ab899d3469ca0233cc8064d13f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dde5a1ca8db4510ad10cfab1864a4df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dfb41e19c7645019bea35e7c38bf706":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2526846992fa42a6b8a3b1c51fb24da9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d205433b8b04f2abcced7d68562c5b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdf8eee6cc8e4d08b254c5d833a6ed6d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fed2d4d2f1fa4b47a2b687d47cee8f15","IPY_MODEL_fc08531293f541b8858af33fbae15c59","IPY_MODEL_388f1a1f9d2a46599b60bdd63c450c34"],"layout":"IPY_MODEL_6398a2fe6d9246a9baccb00fef9e98cf"}},"fed2d4d2f1fa4b47a2b687d47cee8f15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_211f975e27484454819ff088470c3136","placeholder":"​","style":"IPY_MODEL_d97cca25fcaf48228cbd867c1a9741a1","value":"Downloading pytorch_model.bin: 100%"}},"fc08531293f541b8858af33fbae15c59":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f3d4026c1f84ee1b54db8d2e19c6c54","max":72439832,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea8a8e6acf2940bf9f5aba7f41920638","value":72439832}},"388f1a1f9d2a46599b60bdd63c450c34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69a8f2079bd34780938c59ed187fb8c8","placeholder":"​","style":"IPY_MODEL_3f948caaa4c944d6a8182926f1f9ef7d","value":" 72.4M/72.4M [00:00&lt;00:00, 114MB/s]"}},"6398a2fe6d9246a9baccb00fef9e98cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"211f975e27484454819ff088470c3136":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d97cca25fcaf48228cbd867c1a9741a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f3d4026c1f84ee1b54db8d2e19c6c54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea8a8e6acf2940bf9f5aba7f41920638":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69a8f2079bd34780938c59ed187fb8c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f948caaa4c944d6a8182926f1f9ef7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd drive/MyDrive/Colab Notebooks/Thesis Project/"],"metadata":{"executionInfo":{"elapsed":2944,"status":"ok","timestamp":1688236568419,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"},"user_tz":-360},"id":"PZPZh5lih2OW","outputId":"631cf2de-87e7-4905-9a54-b0fe8de0893d","execution":{"iopub.status.busy":"2023-07-01T14:05:20.399268Z","iopub.execute_input":"2023-07-01T14:05:20.399539Z","iopub.status.idle":"2023-07-01T14:05:20.418749Z","shell.execute_reply.started":"2023-07-01T14:05:20.399515Z","shell.execute_reply":"2023-07-01T14:05:20.417580Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/Thesis Project/'\n","/content/drive/MyDrive/Colab Notebooks/Thesis Project\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"pHqoUgY3urW-","executionInfo":{"status":"ok","timestamp":1688236568420,"user_tz":-360,"elapsed":5,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"4a9f866d-d6c3-4438-8b5a-f8035324338e","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["'0. All Datasets_Processed .gsheet'\n","'0. All Datasets_Processed.xlsx'\n","'0. All Datasets.xlsx'\n","'0. Depression Analysis Dataset.xlsx'\n","'1. Depression Analysis Dataset Cleaned v1.xlsx'\n","'1. Depression Analysis Dataset Cleaned v2.xlsx'\n","'1. Depression Analysis Dataset Cleaned v3_textcleaned.xlsx'\n","'1. Depression Analysis Dataset Cleaned v3_textstemmed.xlsx'\n","'1. Depression Analysis v1.ipynb'\n","'2.1 Depression Analysis v2 (Previous code).ipynb'\n","'2.2 Depression Analysis v2.ipynb'\n","'2.3 Depression Analysis v2 modified.ipynb'\n","'3.1 Depression_Analysis_v3.ipynb'\n","'3.2 Depression_Analysis_v3 (Word2Vec).ipynb'\n","'3.3 Depression_Analysis_v3 (FastText).ipynb'\n","'3.4 Depression_Analysis_LSTM_FastText.ipynb'\n","'3.4 Depression_Analysis_v3 (Glove).ipynb'\n","'3.5 Depression_Analysis_BiLSTM_FastText.ipynb'\n","'4.1 Depression_Analysis_v4 (New Tokenizer).ipynb'\n","'4.2 Depression_Analysis_v4_Lemmatize.ipynb'\n","'4.3 Depression_Analysis_v4_Stem.ipynb'\n","'4.4 Depression_Analysis (Hyperparameter Tuning).ipynb'\n","'5.1 BanglaBert.ipynb'\n","'5.2 Bert3_SGD_Optimizer.ipynb'\n","'5.3 BanglaBert.ipynb'\n"," best_model_fold1.pth\n"," best_model.pth\n"," content\n","'Depression_Analysis (Bayesian Optimization).ipynb'\n"," ML-Fraud-Detection-using-XAI.ipynb\n"," preprocessed_dataset.csv\n"," sahajbert.ipynb\n"," state_dict.pt\n"," xlm-roberta-large-sized-model.ipynb\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"execution":{"iopub.status.busy":"2023-07-01T14:05:20.421147Z","iopub.execute_input":"2023-07-01T14:05:20.421602Z","iopub.status.idle":"2023-07-01T14:05:35.606891Z","shell.execute_reply.started":"2023-07-01T14:05:20.421568Z","shell.execute_reply":"2023-07-01T14:05:35.605683Z"},"trusted":true,"id":"1pP_9xynuevf","outputId":"ccecf912-1f06-4b8e-e0eb-733a80798c90","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688236601412,"user_tz":-360,"elapsed":19781,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"]}]},{"cell_type":"code","source":["# pip install git+https://github.com/csebuetnlp/normalizer #BanglaBert"],"metadata":{"execution":{"iopub.status.busy":"2023-07-01T14:05:35.610293Z","iopub.execute_input":"2023-07-01T14:05:35.610610Z","iopub.status.idle":"2023-07-01T14:05:35.615278Z","shell.execute_reply.started":"2023-07-01T14:05:35.610580Z","shell.execute_reply":"2023-07-01T14:05:35.614324Z"},"trusted":true,"id":"db0jXoZnuevf","executionInfo":{"status":"ok","timestamp":1688236601412,"user_tz":-360,"elapsed":3,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","from transformers import BertModel, BertTokenizer\n","from transformers import AutoTokenizer\n","# from transformers import AutoModelForPreTraining, ElectraModel, ElectraTokenizer #BanglaBert\n","from transformers import AlbertModel, PreTrainedTokenizerFast #sahajBERT\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold"],"metadata":{"execution":{"iopub.status.busy":"2023-07-01T14:05:35.616763Z","iopub.execute_input":"2023-07-01T14:05:35.617297Z","iopub.status.idle":"2023-07-01T14:05:49.878132Z","shell.execute_reply.started":"2023-07-01T14:05:35.617262Z","shell.execute_reply":"2023-07-01T14:05:49.877016Z"},"trusted":true,"id":"hJK8Jd3guevf","executionInfo":{"status":"ok","timestamp":1688236612013,"user_tz":-360,"elapsed":10604,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["print(torch.__version__)"],"metadata":{"execution":{"iopub.status.busy":"2023-07-01T14:05:49.880705Z","iopub.execute_input":"2023-07-01T14:05:49.881038Z","iopub.status.idle":"2023-07-01T14:05:49.886889Z","shell.execute_reply.started":"2023-07-01T14:05:49.880999Z","shell.execute_reply":"2023-07-01T14:05:49.885828Z"},"trusted":true,"id":"aFYfuVH2uevg","outputId":"b8b2ec84-2ff0-4e36-cfb4-0494e817e2b1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688236612014,"user_tz":-360,"elapsed":3,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.1+cu118\n"]}]},{"cell_type":"code","source":["# Load the data\n","df = pd.read_excel('0. All Datasets.xlsx')\n","# df = pd.read_excel('0. All Datasets_Processed.xlsx')\n","df['label'] = df['label'].map({'Non Depressive': 0, 'Depressive': 1})\n","# Drop rows with any missing values\n","df = df.dropna(subset=['text', 'label'])\n","# drop rows that have identical values in all columns\n","df.drop_duplicates(inplace=True)\n","\n","# Assuming your DataFrame is named 'df'\n","columns_to_drop = [col for col in df.columns if col not in ['text', 'label']]\n","df.drop(columns=columns_to_drop, inplace=True)\n","\n","print(df.info())\n","\n","label_counts = df['label'].value_counts()\n","print(\"Label Details:\")\n","print(label_counts)\n","\n","df.sample(n=10)  # Change the value of 'n' to the desired number of random samples"],"metadata":{"id":"erIPs2Khoevg","executionInfo":{"status":"ok","timestamp":1688236893318,"user_tz":-360,"elapsed":13259,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"732e0404-3d84-4fc0-8987-371de97c1ff3","execution":{"iopub.status.busy":"2023-07-01T14:05:49.888584Z","iopub.execute_input":"2023-07-01T14:05:49.889367Z","iopub.status.idle":"2023-07-01T14:05:59.637183Z","shell.execute_reply.started":"2023-07-01T14:05:49.889332Z","shell.execute_reply":"2023-07-01T14:05:59.636096Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":606}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 31695 entries, 0 to 31698\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   text    31695 non-null  object\n"," 1   label   31695 non-null  int64 \n","dtypes: int64(1), object(1)\n","memory usage: 742.9+ KB\n","None\n","Label Details:\n","0    16719\n","1    14976\n","Name: label, dtype: int64\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                    text  label\n","23558  আমি যতটা বড় মহাকাব্যিক ছবিগুলি পছন্দ করি - আম...      0\n","16722  স্কুল অর্থহীন যদি আপনি এমন কিছুর জন্য অধ্যয়ন ...      0\n","1724   তাই কিছু পিছনের গল্প, আমার বোন সবসময় আমার সের...      1\n","6611   সত্যিই ঘৃণা করি এই মহামারী চলাকালীন আমার মস্তি...      0\n","22775  আপনি কি আমাকে এই বাচ্চাটির শো খুঁজে পেতে সাহায...      0\n","3639   আমার গ্রেড কমে যাচ্ছে এবং আমি আতঙ্কিত, কিন্তু ...      0\n","13383  হ্যালো, আমার বাবা যিনি বেশ আপত্তিজনক এবং আমার ...      1\n","7752   মাফ করবেন আমার ব্যাকরণ, ইংরেজি আমার প্রথম ভাষা...      1\n","16581  একটি টয়লেট যা একটি ড্রেসারের মতো ডিজাইন করা হ...      0\n","5349   আমি আপনি গ্রাহ্য না জানি. এখন কয়েক মাস হয়ে গ...      1"],"text/html":["\n","  <div id=\"df-d68e5e4b-8869-4e33-b15b-a52aa94c9c4e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>23558</th>\n","      <td>আমি যতটা বড় মহাকাব্যিক ছবিগুলি পছন্দ করি - আম...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16722</th>\n","      <td>স্কুল অর্থহীন যদি আপনি এমন কিছুর জন্য অধ্যয়ন ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1724</th>\n","      <td>তাই কিছু পিছনের গল্প, আমার বোন সবসময় আমার সের...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6611</th>\n","      <td>সত্যিই ঘৃণা করি এই মহামারী চলাকালীন আমার মস্তি...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22775</th>\n","      <td>আপনি কি আমাকে এই বাচ্চাটির শো খুঁজে পেতে সাহায...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3639</th>\n","      <td>আমার গ্রেড কমে যাচ্ছে এবং আমি আতঙ্কিত, কিন্তু ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13383</th>\n","      <td>হ্যালো, আমার বাবা যিনি বেশ আপত্তিজনক এবং আমার ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7752</th>\n","      <td>মাফ করবেন আমার ব্যাকরণ, ইংরেজি আমার প্রথম ভাষা...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16581</th>\n","      <td>একটি টয়লেট যা একটি ড্রেসারের মতো ডিজাইন করা হ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5349</th>\n","      <td>আমি আপনি গ্রাহ্য না জানি. এখন কয়েক মাস হয়ে গ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d68e5e4b-8869-4e33-b15b-a52aa94c9c4e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d68e5e4b-8869-4e33-b15b-a52aa94c9c4e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d68e5e4b-8869-4e33-b15b-a52aa94c9c4e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Sample 14,000 instances for each label\n","df_label_0 = df[df['label'] == 0].sample(n=14000)\n","df_label_1 = df[df['label'] == 1].sample(n=14000)\n","\n","# Concatenate the sampled dataframes\n","df = pd.concat([df_label_0, df_label_1], ignore_index=True)\n","\n","print(df.info())\n","\n","label_counts = df['label'].value_counts()\n","print(\"Label Details:\")\n","print(label_counts)\n","\n","df.sample(n=10)  # Change the value of 'n' to the desired number of random samples"],"metadata":{"id":"brJpM3Cap_ze","executionInfo":{"status":"ok","timestamp":1688236893318,"user_tz":-360,"elapsed":4,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"be58f895-f9a1-4312-9d2e-9a886a14d06c","execution":{"iopub.status.busy":"2023-07-01T14:05:59.638507Z","iopub.execute_input":"2023-07-01T14:05:59.640210Z","iopub.status.idle":"2023-07-01T14:05:59.679326Z","shell.execute_reply.started":"2023-07-01T14:05:59.640174Z","shell.execute_reply":"2023-07-01T14:05:59.678237Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":606}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 28000 entries, 0 to 27999\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   text    28000 non-null  object\n"," 1   label   28000 non-null  int64 \n","dtypes: int64(1), object(1)\n","memory usage: 437.6+ KB\n","None\n","Label Details:\n","0    14000\n","1    14000\n","Name: label, dtype: int64\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                    text  label\n","834    জিনো কস্তা (ম্যাসিমো গিরোত্তি) একজন তরুণ এবং স...      0\n","24101  সাহায্য করুন. কয়েক বছর ধরে আমি একটি গুরুতর বি...      1\n","7910   অনুগ্রহ করে সাহায্য করুন আমার একটি জ্ঞানীয় অস...      0\n","5794   সবেমাত্র গতকাল মনস্টার ম্যানকে দেখতে পেয়েছিলা...      0\n","4563   বেশিরভাগ মেয়েই জানে না তারা আসলে কি চায়। একট...      0\n","22899  আমি এবং আমার মা যুগ যুগ ধরে একত্রিত হইনি। আমি ...      1\n","6664   আমি কি করব?!?! তাই প্রায় 2 বছর আগে আমি 8ম শ্র...      0\n","5790   আমার কি আমার ভাইয়ের মুখোমুখি হতে হবে? আমার ভা...      0\n","5769   আমি এটা ঘৃণা করি যখন লোকেরা এমন আচরণ করে যে তা...      0\n","7356   দয়া করে লোকেদের শ্বাসরোধ করবেন না তাই আমি একট...      0"],"text/html":["\n","  <div id=\"df-4c14d29f-bd9e-413b-9a85-31e57a741c50\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>834</th>\n","      <td>জিনো কস্তা (ম্যাসিমো গিরোত্তি) একজন তরুণ এবং স...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24101</th>\n","      <td>সাহায্য করুন. কয়েক বছর ধরে আমি একটি গুরুতর বি...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7910</th>\n","      <td>অনুগ্রহ করে সাহায্য করুন আমার একটি জ্ঞানীয় অস...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5794</th>\n","      <td>সবেমাত্র গতকাল মনস্টার ম্যানকে দেখতে পেয়েছিলা...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4563</th>\n","      <td>বেশিরভাগ মেয়েই জানে না তারা আসলে কি চায়। একট...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22899</th>\n","      <td>আমি এবং আমার মা যুগ যুগ ধরে একত্রিত হইনি। আমি ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6664</th>\n","      <td>আমি কি করব?!?! তাই প্রায় 2 বছর আগে আমি 8ম শ্র...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5790</th>\n","      <td>আমার কি আমার ভাইয়ের মুখোমুখি হতে হবে? আমার ভা...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5769</th>\n","      <td>আমি এটা ঘৃণা করি যখন লোকেরা এমন আচরণ করে যে তা...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7356</th>\n","      <td>দয়া করে লোকেদের শ্বাসরোধ করবেন না তাই আমি একট...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c14d29f-bd9e-413b-9a85-31e57a741c50')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4c14d29f-bd9e-413b-9a85-31e57a741c50 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4c14d29f-bd9e-413b-9a85-31e57a741c50');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["X = df['text']\n","y = df['label']\n","print(X.info())\n","print(y.info())"],"metadata":{"id":"mTmJIuExpeY3","executionInfo":{"status":"ok","timestamp":1688236894200,"user_tz":-360,"elapsed":2,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"ce978fc5-11fd-4b39-e7f1-bd4d5723dec6","execution":{"iopub.status.busy":"2023-07-01T14:05:59.680784Z","iopub.execute_input":"2023-07-01T14:05:59.682956Z","iopub.status.idle":"2023-07-01T14:05:59.702004Z","shell.execute_reply.started":"2023-07-01T14:05:59.682912Z","shell.execute_reply":"2023-07-01T14:05:59.700818Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.series.Series'>\n","RangeIndex: 28000 entries, 0 to 27999\n","Series name: text\n","Non-Null Count  Dtype \n","--------------  ----- \n","28000 non-null  object\n","dtypes: object(1)\n","memory usage: 218.9+ KB\n","None\n","<class 'pandas.core.series.Series'>\n","RangeIndex: 28000 entries, 0 to 27999\n","Series name: label\n","Non-Null Count  Dtype\n","--------------  -----\n","28000 non-null  int64\n","dtypes: int64(1)\n","memory usage: 218.9 KB\n","None\n"]}]},{"cell_type":"code","source":["# Define batch size\n","BATCH_SIZE = 32\n","LEARNING_RATE = 0.01\n","\n","DROPOUT = 0.1\n","\n","# Training loop\n","NUM_EPOCHS = 10\n","\n","# Define number of folds for cross-validation\n","NUM_FOLDS = 5\n","\n","# Momentum -> hyperparameter of Stochastic Gradient Descent (SGD) optimizer\n","MOMENTUM = 0.9\n"],"metadata":{"execution":{"iopub.status.busy":"2023-07-01T14:05:59.703761Z","iopub.execute_input":"2023-07-01T14:05:59.704122Z","iopub.status.idle":"2023-07-01T14:05:59.711988Z","shell.execute_reply.started":"2023-07-01T14:05:59.704089Z","shell.execute_reply":"2023-07-01T14:05:59.711020Z"},"trusted":true,"id":"yN4lei1tuevg","executionInfo":{"status":"ok","timestamp":1688236917845,"user_tz":-360,"elapsed":341,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# Define the BERT model architecture"],"metadata":{"id":"2seNRUyUTH-s"}},{"cell_type":"code","source":["# Define the BERT model architecture\n","class BERTClassifier(nn.Module):\n","    def __init__(self, bert_model, hidden_dim, num_classes):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert_model\n","        self.dropout = nn.Dropout(DROPOUT)\n","        self.fc = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = output['pooler_output']\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.fc(pooled_output)\n","        return torch.sigmoid(logits)\n","\n","\n","# Set device\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# model_identifier = 'bert-base-multilingual-cased'\n","# model_identifier ='csebuetnlp/banglabert'\n","model_identifier = 'neuropark/sahajBERT'\n","\n","# Load the BERT tokenizer and encode the text data\n","# tokenizer = BertTokenizer.from_pretrained(model_identifier)\n","# tokenizer = AutoTokenizer.from_pretrained('csebuetnlp/banglabert')\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(model_identifier)\n","\n","X_encodings = tokenizer(list(X), truncation=True, padding=True, max_length=512)\n","\n","# Convert labels to tensor\n","y_tensor = torch.tensor(y.values)\n","\n","# Initialize the StratifiedKFold\n","skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n","\n","# Perform cross-validation\n","for fold, (train_index, val_index) in enumerate(skf.split(X_encodings['input_ids'], y_tensor), 1):\n","    print(f\"Processing Fold: {fold}\")\n","\n","    # Convert X_encodings to a list of tuples\n","    X_encodings_list = list(X_encodings.items())\n","\n","    # Split data into train and validation sets\n","    X_train_fold = {key: [value[i] for i in train_index] for key, value in X_encodings_list}\n","    X_val_fold = {key: [value[i] for i in val_index] for key, value in X_encodings_list}\n","    y_train_fold = y_tensor[train_index]\n","    y_val_fold = y_tensor[val_index]\n","\n","\n","    # Create PyTorch datasets\n","    train_dataset = TensorDataset(torch.tensor(X_train_fold['input_ids']),\n","                                  torch.tensor(X_train_fold['attention_mask']),\n","                                  torch.tensor(y_train_fold))\n","    val_dataset = TensorDataset(torch.tensor(X_val_fold['input_ids']),\n","                                torch.tensor(X_val_fold['attention_mask']),\n","                                torch.tensor(y_val_fold))\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"],"metadata":{"execution":{"iopub.status.busy":"2023-07-01T14:06:34.924589Z","iopub.execute_input":"2023-07-01T14:06:34.924996Z","iopub.status.idle":"2023-07-01T14:07:41.454393Z","shell.execute_reply.started":"2023-07-01T14:06:34.924964Z","shell.execute_reply":"2023-07-01T14:07:41.453422Z"},"trusted":true,"colab":{"referenced_widgets":["ae1730e6c5534d1bb52b8a412b55dcca","a8abd75c101c4dc88cd837093dc572e2","1be35d76135f403c8a9bc4362f158c0e","3d228f2335744a6690dd38b5dd94a7a4","25df1b29975b49bc98424ec24e528029","b9509f41abe348df97b98ab9317ee985","7d51b1cca053421bbe53b16acce06414","dfd2fdaefc2940c8ad2ed98813fa97ce","4ee887abc6c24ffc943c37141656b6ee","c89634a3d2b54a1f8528a3a7f6faa8cf","dc55d166a2fb466a882231db36164821","14c4a9791c02450f9e2338cc1d3a2bef","a82adb2c0f3243d2a4f885e7d248021c","54cf469d84b94df9bc0deac6fce02f73","07d9fb1123c44d0fba5a0ae8aad1bfc5","1e962b1540de4c8d9f33d54abd39238c","187121d668e846b79cadd5dddc489518","df1f136d4d7046e2af1e5673b0d69ba7","6928c394db964421ac6f586c1a259c41","8772d2689c9544fbabab25b6adb43bea","a90f8a518109468e92706a9a6b87814d","46c87449aba440b78a45c5b5ea320c24","a1aad02853c44c808a918dd0782f0418","00e98e5f24734258bd979b72a25b30ab","9bb5a3240bbd4f7381d4410b66e46af3","14dd20d2286d4c568ec4d36626127584","f18d3d123e864456a72ce9374e8e8685","9e88cd13e794417e8330280f7bda8bc9","4eba0a2fd5c84775b88fe502bd4a57e5","30b82e7420ff4b4e8338c2b75c266f84","19d2870acd75415db953f17dc5959cf3","ab22a99c524e4090b6952fe2e8325452","044f9139274a48acac6e8a174e5875f8","8b33181428664be49f3bd48dfef779ef","ec7c27b8b1ff4a09ae3b6030a3e54a99","e28eb5d2ed1b4bd78fc802bc57d1c2d9","3444371b56864d25ace90e243b0cb743","ef7227b049fc4b80a18bacc240f8aea0","17f7ce7dee6a4338af9c2c4270f84c27","fca03ab899d3469ca0233cc8064d13f6","2dde5a1ca8db4510ad10cfab1864a4df","5dfb41e19c7645019bea35e7c38bf706","2526846992fa42a6b8a3b1c51fb24da9","3d205433b8b04f2abcced7d68562c5b6"],"base_uri":"https://localhost:8080/","height":321},"id":"gmskGzgHuevh","outputId":"0aaf6a12-5231-448a-d3d0-df510c11f6b5","executionInfo":{"status":"ok","timestamp":1688237005883,"user_tz":-360,"elapsed":79910,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/471 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae1730e6c5534d1bb52b8a412b55dcca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14c4a9791c02450f9e2338cc1d3a2bef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/322 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1aad02853c44c808a918dd0782f0418"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/813 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b33181428664be49f3bd48dfef779ef"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-774b713c160b>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(y_train_fold))\n","<ipython-input-18-774b713c160b>:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(y_val_fold))\n"]},{"output_type":"stream","name":"stdout","text":["Processing Fold: 2\n","Processing Fold: 3\n","Processing Fold: 4\n","Processing Fold: 5\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Define the BERT classifier model\n","class BERTClassifier(nn.Module):\n","    def __init__(self, bert_model, hidden_dim, num_classes):\n","        super(BERTClassifier, self).__init__()\n","        self.bert_model = bert_model\n","        self.fc = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.bert_model(input_ids, attention_mask)[1]  # Use the [CLS] token representation\n","        logits = self.fc(output)\n","        return logits\n","\n","# Set the device\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the BERT model\n","# bert_model = BertModel.from_pretrained(model_identifier)\n","bert_model = AlbertModel.from_pretrained(\"neuropark/sahajBERT\")\n","\n","\n","hidden_dim = bert_model.config.hidden_size\n","num_classes = 2\n","#bert_model = torch.compile(bert_model)\n","model = BERTClassifier(bert_model, hidden_dim, num_classes).to(DEVICE)\n","# model = torch.compile(model)\n","\n","# Define the optimizer and loss function\n","# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","best_accuracy = 0.0\n","\n","# Freeze BERT layer\n","for param in model.bert_model.parameters():\n","    param.requires_grad = False\n","\n","# Unfreeze output layer\n","for param in model.fc.parameters():\n","    param.requires_grad = True\n","\n","# Define lists to store metrics for each fold\n","fold_train_losses = []\n","fold_train_accuracies = []\n","fold_val_losses = []\n","fold_val_accuracies = []\n","fold_val_predictions = []\n","fold_val_labels = []\n","\n","# Define lists to store train and validation metrics per epoch\n","train_losses_per_epoch = []\n","train_accuracies_per_epoch = []\n","val_losses_per_epoch = []\n","val_accuracies_per_epoch = []\n","\n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","\n","    for batch in train_loader:\n","      input_ids, attention_mask, labels = batch\n","      input_ids = input_ids.to(DEVICE)\n","      attention_mask = attention_mask.to(DEVICE)\n","      labels = labels.to(DEVICE)\n","\n","      optimizer.zero_grad()\n","\n","      logits = model(input_ids, attention_mask)\n","      _, predicted = torch.max(logits, 1)\n","\n","      loss = criterion(logits, labels)\n","      loss.backward()\n","      optimizer.step()\n","\n","      train_loss += loss.item() * input_ids.size(0)\n","      train_total += labels.size(0)\n","      train_correct += (predicted == labels).sum().item()\n","\n","    train_accuracy = 100 * train_correct / train_total\n","\n","    model.eval()\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","\n","    with torch.no_grad():\n","        for batch in val_loader:\n","          input_ids, attention_mask, labels = batch\n","          input_ids = input_ids.to(DEVICE)\n","          attention_mask = attention_mask.to(DEVICE)\n","          labels = labels.to(DEVICE)\n","\n","          logits = model(input_ids, attention_mask)\n","          _, predicted = torch.max(logits, 1)\n","\n","          loss = criterion(logits, labels)\n","\n","          val_loss += loss.item() * input_ids.size(0)\n","          val_total += labels.size(0)\n","          val_correct += (predicted == labels).sum().item()\n","\n","          fold_val_predictions.extend(predicted.cpu().numpy())\n","          fold_val_labels.extend(labels.cpu().numpy())\n","\n","    val_accuracy = 100 * val_correct / val_total\n","\n","    fold_train_losses.append(train_loss / train_total)\n","    fold_train_accuracies.append(train_accuracy)\n","    fold_val_losses.append(val_loss / val_total)\n","    fold_val_accuracies.append(val_accuracy)\n","\n","    train_losses_per_epoch.append(train_loss / train_total)\n","    train_accuracies_per_epoch.append(train_accuracy)\n","    val_losses_per_epoch.append(val_loss / val_total)\n","    val_accuracies_per_epoch.append(val_accuracy)\n","\n","    print('Epoch: {}/{} | Train Loss: {:.4f} | Train Accuracy: {:.2f}% | Val Loss: {:.4f} | Val Accuracy: {:.2f}%'.format(\n","        epoch + 1, NUM_EPOCHS, train_loss / train_total, train_accuracy, val_loss / val_total, val_accuracy))\n","\n","    if val_accuracy > best_accuracy:\n","        best_accuracy = val_accuracy\n","        torch.save(model.state_dict(), 'best_model.pth')\n","\n","# Calculate performance metrics\n","average_accuracy = accuracy_score(fold_val_labels, fold_val_predictions)\n","average_precision = precision_score(fold_val_labels, fold_val_predictions)\n","average_recall = recall_score(fold_val_labels, fold_val_predictions)\n","average_f1_score = f1_score(fold_val_labels, fold_val_predictions)\n","\n","# Print average metrics across folds\n","print('Average Metrics Across Folds:')\n","print('Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f} | F1 Score: {:.4f}'.format(\n","    average_accuracy, average_precision, average_recall, average_f1_score))\n","\n","# Plotting the train and validation accuracy and loss graphs\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(train_losses_per_epoch, label='Train Loss')\n","plt.plot(val_losses_per_epoch, label='Val Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(train_accuracies_per_epoch, label='Train Accuracy')\n","plt.plot(val_accuracies_per_epoch, label='Val Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"execution":{"iopub.status.busy":"2023-07-01T14:07:41.456341Z","iopub.execute_input":"2023-07-01T14:07:41.457046Z"},"trusted":true,"colab":{"referenced_widgets":["bdf8eee6cc8e4d08b254c5d833a6ed6d","fed2d4d2f1fa4b47a2b687d47cee8f15","fc08531293f541b8858af33fbae15c59","388f1a1f9d2a46599b60bdd63c450c34","6398a2fe6d9246a9baccb00fef9e98cf","211f975e27484454819ff088470c3136","d97cca25fcaf48228cbd867c1a9741a1","1f3d4026c1f84ee1b54db8d2e19c6c54","ea8a8e6acf2940bf9f5aba7f41920638","69a8f2079bd34780938c59ed187fb8c8","3f948caaa4c944d6a8182926f1f9ef7d"],"base_uri":"https://localhost:8080/","height":485},"id":"l9o5wtFNuevi","outputId":"fcaac5bc-a81e-4c5e-fb54-94d468b7fcb6","executionInfo":{"status":"error","timestamp":1688238144813,"user_tz":-360,"elapsed":1138938,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}}},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/72.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdf8eee6cc8e4d08b254c5d833a6ed6d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at neuropark/sahajBERT were not used when initializing AlbertModel: ['sop_classifier.classifier.bias', 'predictions.dense.bias', 'predictions.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.decoder.weight', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.bias']\n","- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-f3353d99f624>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-f3353d99f624>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Use the [CLS] token representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         )\n\u001b[0;32m--> 730\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mgroup_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             layer_group_output = self.albert_layer_groups[group_idx](\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbert_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malbert_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         ffn_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff_chunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mff_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"J2s52eiauevi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the BERT model architecture\n","class BERTClassifier(nn.Module):\n","    def __init__(self, bert_model, hidden_dim, num_classes):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert_model\n","        self.dropout = nn.Dropout(DROPOUT)\n","        self.fc = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = output['pooler_output']\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.fc(pooled_output)\n","        return torch.sigmoid(logits)\n","\n","\n","# Set device\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Load the BERT tokenizer and encode the text data\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","# tokenizer = AutoTokenizer.from_pretrained('csebuetnlp/banglabert')\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"neuropark/sahajBERT\")\n","\n","# X_normalized = [normalize(text) for text in X]\n","\n","X_encodings = tokenizer(list(X), truncation=True, padding=True, max_length=512)\n","# X_encodings = tokenizer(list(X_normalized), truncation=True, padding=True, max_length=512)\n","\n","\n","# Convert labels to tensor\n","y_tensor = torch.tensor(y.values)\n","\n","# Initialize the StratifiedKFold\n","skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n","\n","# Perform cross-validation\n","for fold, (train_index, val_index) in enumerate(skf.split(X_encodings['input_ids'], y_tensor), 1):\n","    print(f\"Processing Fold: {fold}\")\n","\n","    # Convert X_encodings to a list of tuples\n","    X_encodings_list = list(X_encodings.items())\n","\n","    # Split data into train and validation sets\n","    X_train_fold = {key: [value[i] for i in train_index] for key, value in X_encodings_list}\n","    X_val_fold = {key: [value[i] for i in val_index] for key, value in X_encodings_list}\n","    y_train_fold = y_tensor[train_index]\n","    y_val_fold = y_tensor[val_index]\n","\n","\n","    # Create PyTorch datasets\n","    train_dataset = TensorDataset(torch.tensor(X_train_fold['input_ids']),\n","                                  torch.tensor(X_train_fold['attention_mask']),\n","                                  torch.tensor(y_train_fold))\n","    val_dataset = TensorDataset(torch.tensor(X_val_fold['input_ids']),\n","                                torch.tensor(X_val_fold['attention_mask']),\n","                                torch.tensor(y_val_fold))\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n"],"metadata":{"executionInfo":{"elapsed":173206,"status":"ok","timestamp":1686912141593,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"},"user_tz":-360},"id":"lRjZuXCFh6dy","outputId":"f76841e6-d130-4ef3-df37-7446b479a3c5","execution":{"iopub.status.busy":"2023-06-30T20:47:11.450047Z","iopub.execute_input":"2023-06-30T20:47:11.450508Z","iopub.status.idle":"2023-06-30T20:48:34.410459Z","shell.execute_reply.started":"2023-06-30T20:47:11.450482Z","shell.execute_reply":"2023-06-30T20:48:34.409268Z"},"trusted":true,"colab":{"referenced_widgets":["63b8d5c486214871af450085c82dd8a4","2e51327f75594b4ebebe5ca94cbbda78","db495518510646a79619afe6ca30c9cc","3cf4b813f6ad46519c5936be7d38579a"]}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/471 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63b8d5c486214871af450085c82dd8a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e51327f75594b4ebebe5ca94cbbda78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/322 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db495518510646a79619afe6ca30c9cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/813 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cf4b813f6ad46519c5936be7d38579a"}},"metadata":{}},{"name":"stdout","text":"Processing Fold: 1\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_29/1196739732.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(y_train_fold))\n/tmp/ipykernel_29/1196739732.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(y_val_fold))\n","output_type":"stream"},{"name":"stdout","text":"Processing Fold: 2\nProcessing Fold: 3\nProcessing Fold: 4\nProcessing Fold: 5\n","output_type":"stream"}]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n"],"metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:48:34.412130Z","iopub.execute_input":"2023-06-30T20:48:34.412535Z","iopub.status.idle":"2023-06-30T20:48:34.420237Z","shell.execute_reply.started":"2023-06-30T20:48:34.412499Z","shell.execute_reply":"2023-06-30T20:48:34.417659Z"},"trusted":true,"id":"QIMezG0Puevj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Define the BERT classifier model\n","class BERTClassifier(nn.Module):\n","    def __init__(self, bert_model, hidden_dim, num_classes):\n","        super(BERTClassifier, self).__init__()\n","        self.bert_model = bert_model\n","        self.fc = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.bert_model(input_ids=input_ids, attention_mask=attention_mask)\n","        cls_output = output.last_hidden_state[:, 0, :]  # Use the [CLS] token representation\n","        logits = self.fc(cls_output)\n","        return logits\n","\n","# Set the device\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the BERT model\n","# bert_model = ElectraModel.from_pretrained('csebuetnlp/banglabert')\n","bert_model = AlbertModel.from_pretrained(\"neuropark/sahajBERT\")\n","\n","hidden_dim = bert_model.config.hidden_size\n","num_classes = 2\n","\n","model = BERTClassifier(bert_model, hidden_dim, num_classes).to(DEVICE)\n","\n","# Define the optimizer and loss function\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n","criterion = nn.CrossEntropyLoss()\n","\n","best_accuracy = 0.0\n","\n","# Freeze BERT layer\n","for param in model.bert_model.parameters():\n","    param.requires_grad = False\n","\n","# Unfreeze output layer\n","for param in model.fc.parameters():\n","    param.requires_grad = True\n","\n","# Define lists to store metrics for each fold\n","fold_train_losses = []\n","fold_train_accuracies = []\n","fold_val_losses = []\n","fold_val_accuracies = []\n","fold_val_predictions = []\n","fold_val_labels = []\n","\n","# Define lists to store train and validation metrics per epoch\n","train_losses_per_epoch = []\n","train_accuracies_per_epoch = []\n","val_losses_per_epoch = []\n","val_accuracies_per_epoch = []\n","\n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","\n","    for batch in train_loader:\n","        input_ids, attention_mask, labels = batch\n","        input_ids = input_ids.to(DEVICE)\n","        attention_mask = attention_mask.to(DEVICE)\n","        labels = labels.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","\n","        logits = model(input_ids, attention_mask)\n","        _, predicted = torch.max(logits, 1)\n","\n","        # Convert labels to one-dimensional tensor\n","        labels = labels.squeeze()\n","\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item() * input_ids.size(0)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","\n","    train_accuracy = 100 * train_correct / train_total\n","\n","    model.eval()\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            input_ids, attention_mask, labels = batch\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","\n","            logits = model(input_ids, attention_mask)\n","            _, predicted = torch.max(logits, 1)\n","\n","            loss = criterion(logits, labels)\n","\n","            val_loss += loss.item() * input_ids.size(0)\n","            val_total += labels.size(0)\n","            val_correct += (predicted == labels).sum().item()\n","\n","            fold_val_predictions.extend(predicted.cpu().numpy())\n","            fold_val_labels.extend(labels.cpu().numpy())\n","\n","    val_accuracy = 100 * val_correct / val_total\n","\n","    fold_train_losses.append(train_loss / train_total)\n","    fold_train_accuracies.append(train_accuracy)\n","    fold_val_losses.append(val_loss / val_total)\n","    fold_val_accuracies.append(val_accuracy)\n","\n","    train_losses_per_epoch.append(train_loss / train_total)\n","    train_accuracies_per_epoch.append(train_accuracy)\n","    val_losses_per_epoch.append(val_loss / val_total)\n","    val_accuracies_per_epoch.append(val_accuracy)\n","\n","    print('Epoch: {}/{} | Train Loss: {:.4f} | Train Accuracy: {:.2f}% | Val Loss: {:.4f} | Val Accuracy: {:.2f}%'.format(\n","        epoch + 1, NUM_EPOCHS, train_loss / train_total, train_accuracy, val_loss / val_total, val_accuracy))\n","\n","    if val_accuracy > best_accuracy:\n","        best_accuracy = val_accuracy\n","        torch.save(model.state_dict(), 'best_model.pth')\n","\n","# Calculate performance metrics\n","average_accuracy = accuracy_score(fold_val_labels, fold_val_predictions)\n","average_precision = precision_score(fold_val_labels, fold_val_predictions)\n","average_recall = recall_score(fold_val_labels, fold_val_predictions)\n","average_f1_score = f1_score(fold_val_labels, fold_val_predictions)\n","\n","# Print average metrics across folds\n","print('Average Metrics Across Folds:')\n","print('Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f} | F1 Score: {:.4f}'.format(\n","    average_accuracy, average_precision, average_recall, average_f1_score))\n","\n","# Plotting the train and validation accuracy and loss graphs\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(train_losses_per_epoch, label='Train Loss')\n","plt.plot(val_losses_per_epoch, label='Val Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(train_accuracies_per_epoch, label='Train Accuracy')\n","plt.plot(val_accuracies_per_epoch, label='Val Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"trusted":true,"id":"5kOG0rxKuevj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print hyperparameters\n","print('Hyperparameters:')\n","print('Batch Size:', BATCH_SIZE)\n","print('Learning Rate:', LEARNING_RATE)\n","print('Dropout:', DROPOUT)\n","print('Number of Epochs:', NUM_EPOCHS)\n","print('Number of Folds:', NUM_FOLDS)\n","print('Momentum:', MOMENTUM)\n","\n","# Print average metrics across folds\n","print('Average Metrics Across Folds:')\n","print('Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f} | F1 Score: {:.4f}'.format(\n","    average_accuracy, average_precision, average_recall, average_f1_score))"],"metadata":{"trusted":true,"id":"Gss1abGAuevj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TqCGDxBCuevj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wWmqvw90uevj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0lfMzawiuevj"},"execution_count":null,"outputs":[]}]}